ğŸš Gesture-Based Drone Control System
ğŸ‡°ğŸ‡· í”„ë¡œì íŠ¸ ìš”ì•½ (Korean Summary)
ë³¸ í”„ë¡œì íŠ¸ëŠ” ì›¹ìº  ì˜ìƒì—ì„œ ì† ì œìŠ¤ì²˜ë¥¼ ì¸ì‹í•˜ê³ ,
ì†ê°€ë½ ê°œìˆ˜ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ì—¬ ë“œë¡ ì˜ ë¬¼ë¦¬ì  ë™ì‘(ì´ë¥™, ì´ë™, ì°©ë¥™)ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

MediaPipe ê¸°ë°˜ ì† ëœë“œë§ˆí¬ ì¶”ì¶œê³¼ e_drone ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬
ë¹„ì „ ì¸ì‹ â†’ ì•ˆì •ì„± íŒë‹¨ â†’ í•˜ë“œì›¨ì–´ ì œì–´ ì „ì²´ íë¦„ì„ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤.

ë‹¨ìˆœ ì œìŠ¤ì²˜ ì¸ì‹ êµ¬í˜„ì„ ë„˜ì–´ì„œ,
ì‹¤ì œ ë“œë¡  ë¹„í–‰ ì‹¤í—˜ì„ í†µí•´ ë°œìƒí•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê³¼ì •ì— ì¤‘ì ì„ ë‘” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

ğŸ“Œ Project Overview
This project implements a real-time gesture recognition system that controls a drone using hand gestures detected from a webcam.

System Pipeline

Camera â†’ Hand Landmark Detection â†’ Finger Counting 
â†’ Stability Check â†’ Drone Mission Execution
Rather than focusing only on gesture recognition accuracy,
this project emphasizes system stability, motion control reliability, and hardware-aware design decisions.

ğŸ§  System Architecture
ğŸ”„ Overall Processing Flow
Camera Input (OpenCV)
Hand Landmark Detection (MediaPipe)
Finger Counting Logic
Stable Gesture Confirmation (1 second hold)
Drone Mission Mapping
Motion Execution with Brake & Hover Control
âœ‹ Gesture Recognition Logic
The system detects hand landmarks using MediaPipe and counts extended fingers (0â€“5).

Finger Counting Strategy
Index / Middle / Ring / Pinky

Compare fingertip y-coordinate with lower joint
Thumb

Distance-based comparison between thumb tip and pinky base
More robust against palm/back orientation differences
â± Stability Logic
To avoid unintended drone motion:

The same gesture must be maintained for 1 second
After execution, the hand must be lowered before the next command
Edge-trigger structure prevents repeated execution
This prevents continuous command looping and accidental re-triggering.

ğŸš Drone Motion Control Design
Real-world flight testing revealed several control challenges.

Instead of simple directional commands, the system uses structured control logic:

control() â†’ raw motion control
brake() â†’ short reverse thrust to remove inertia
hover() â†’ trim-based stabilization
Movement Pattern
Move â†’ Brake â†’ Hover
This structure significantly improved motion stability.

ğŸ”§ Experimental Findings & Improvements
1ï¸âƒ£ Hover Instability
Problem: Drone drifted during hover
Solution: Applied trim only in hover stage
2ï¸âƒ£ Inertia After Movement
Problem: Drone did not stop immediately
Solution: Introduced brake control before hover
3ï¸âƒ£ Unexpected Restart Behavior
Problem: After collision or disconnection, previous motion resumed
Solution: Implemented safe_initialize() routine
Repeated landing commands
Control value reset
4ï¸âƒ£ Inconsistent Movement Results
Identical control values produced different distances
Cause: Real-time battery drain affects motor output
Limitation: No API access to real-time battery compensation
ğŸ§© Final Gesture Mapping
Gesture	Action
1

Takeoff

2

Forward

3

Backward

4

Left

5

Right

0

Landing

ğŸ”§ Implementation Details
Language

Python
Libraries

OpenCV (camera processing)
MediaPipe (hand landmark detection)
e_drone (drone control SDK)
NumPy (mathematical utilities)
Environment

Conda virtual environment
Bluetooth communication with CoDrone Mini
ğŸ“‚ Code Structure
Stage	File	Role
Camera Test

camera_test.py

Webcam input verification

Hand Debug

hand_debug.py

Landmark visualization

Gesture Stability

gesture_stable_command.py

Stable gesture detection

Drone Basic Test

drone_basic_test.py

Motion parameter tuning

Drone Missions

drone_missions.py

Movement logic abstraction

Integration

main_gesture_to_drone.py

Full system integration

âš ï¸ Limitations
Battery drain affects motion consistency
No closed-loop position control implemented
Sensor-based compensation not integrated
Flight time limited (~5 minutes)
ğŸ¯ Design Philosophy
âŒ Complex autonomous navigation
â­• Stable real-time control
â­• Hardware-aware parameter tuning
â­• System-level reliability
â­• Safety-first execution logic
This project demonstrates the integration of real-time computer vision with physical drone control, emphasizing stability and practical experimentation over theoretical optimization.

